# ğŸ“š Agentic Research Assistant

An **AI-powered academic research assistant** that helps users **curate their own paper library** and **chat with research context**.  
The system combines **document management**, **retrieval-augmented generation (RAG)**, **multi-stage chain-of-thought reasoning**, and **automatic arXiv integration** to deliver structured academic insights.  

This project is an **Agentic AI system**  not just a chatbot or a RAG pipeline.  
It goes beyond simple Q&A by **reasoning, acting, and adapting**:

- ğŸ§  **Reasoning**: Uses a multi-stage chain-of-thought process (*Exploration â†’ Draft â†’ Reflection â†’ Synthesis*) before answering.  
- âš¡ **Acting**: Takes autonomous actions like fetching arXiv papers, downloading PDFs, chunking, embedding, and summarising them.  
- ğŸ”„ **Adapting**: Expands and updates the userâ€™s personal research library automatically, skipping duplicates and enriching future chats.  

Unlike a static RAG system, this assistant can **plan**, **take decisions**, and **improve its own knowledge base** over time the hallmarks of an **agentic AI** system.  


---

## ğŸš€ Features

### ğŸ“ Paper Management
- Upload your own research **PDFs**.  
- Search and fetch papers directly from **arXiv by keyword**.  
- System automatically:
  - Extracts full text from PDFs  
  - Splits into chunks & creates embeddings (via pgvector)  
  - Generates structured **research-style summaries**  
- View all stored papers and their summaries in your personal library.  

### ğŸ¤– Agentic Chat Assistant
- Ask research questions in natural language.  
- Assistant retrieves relevant papers from your library (RAG).  
- Runs **multi-stage chain-of-thought reasoning** (*Exploration â†’ Draft â†’ Reflection â†’ Synthesis*).  
- If missing knowledge is detected, it can:
  - Extract arXiv IDs from reasoning  
  - Fetch & process new papers automatically  
- Produces structured, academic-style answers in Markdown.  
- Stores all queries, answers, and reasoning transcripts.  

---

## ğŸ› ï¸ Tech Stack

- **Backend:** Python 3.10+, FastAPI, SQLAlchemy  
- **Database:** PostgreSQL + [pgvector](https://github.com/pgvector/pgvector) (for embeddings)  
- **LLM:** Google Gemini (`gemini-1.5-pro`)  
- **Services:**
  - `embedding_service` â†’ creates & saves embeddings  
  - `retrieval_service` â†’ retrieves top-k relevant chunks  
  - `pdf_service` â†’ extracts text & splits into chunks  
  - `arxiv_service` â†’ fetches papers from arXiv API  
  - `summariser_service` â†’ generates structured summaries  
  - `research_assistant` â†’ orchestrates RAG + CoT + agentic paper fetching  

---

## âš™ï¸ How It Works

### ğŸ“¥ Paper Management
1. User uploads a **PDF** or enters an **arXiv keyword**.  
2. System downloads/extracts text â†’ chunks â†’ embeddings.  
3. Generates a **structured summary** (research-style).  
4. Paper, summary, and embeddings are stored for future queries.  

### ğŸ’¬ Chat with Research Assistant
1. User asks a research question.  
2. System embeds query â†’ retrieves **top-k relevant papers**.  
3. Runs **multi-stage reasoning** with context:
   - *Exploration â†’ Draft â†’ Reflection â†’ Synthesis*  
4. If reasoning suggests **new arXiv papers**, system:
   - Verifies ID, downloads PDF, extracts text, creates embeddings, and summarises.  
   - Skips duplicates already in database.  
5. Produces a **final structured answer** in Markdown.  
6. Saves query, answer, and full CoT transcript to DB.  

---
